{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "## 1. Mathematical Foundations (MSc Level)\n",
    "\n",
    "### Entropy\n",
    "$$ H(S) = -\\sum p_i \\log_2(p_i) $$\n",
    "Measure of impurity in a dataset.\n",
    "\n",
    "### Gini Index\n",
    "$$ Gini = 1 - \\sum p_i^2 $$\n",
    "Probability of incorrect classification.\n",
    "\n",
    "### Logistic Regression\n",
    "Uses the sigmoid function:\n",
    "$$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $$\n",
    "Cost function optimized via Gradient Descent.\n",
    "\n",
    "### Metrics\n",
    "- **Precision**: TP / (TP + FP)\n",
    "- **Recall**: TP / (TP + FN)\n",
    "- **F1-Score**: Harmonic mean of Precision and Recall.\n",
    "- **ROC-AUC**: Area under the Receiver Operating Characteristic curve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/student_dropout_1000.csv')\n",
    "\n",
    "# Basic Preprocessing duplication\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Encode Target\n",
    "target = 'Target' if 'Target' in df.columns else df.columns[-1]\n",
    "if df[target].dtype == 'object':\n",
    "    df[target] = df[target].apply(lambda x: 1 if str(x).strip() == 'Dropout' else 0)\n",
    "\n",
    "# Encode others\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if col != target:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        \n",
    "# Fill NaNs\n",
    "df = df.fillna(df.median(numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Splitting and Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(target, axis=1)\n",
    "y = df[target]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random Forest & GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "param_grid = {'n_estimators': [50, 100], 'max_depth': [10, 20, None]}\n",
    "grid = GridSearchCV(rf, param_grid, cv=3, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "best_rf = grid.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Confusion Matrix & ROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix (RF)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_rf, '../models/model.pkl')\n",
    "joblib.dump(scaler, '../models/scaler.pkl')\n",
    "print('Models saved.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}